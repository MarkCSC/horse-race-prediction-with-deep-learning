{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Web-crawling from HKJC"
      ],
      "metadata": {
        "id": "UoVc3A5mL6a8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSgPDgwNWePP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# initialize the url list\n",
        "horse_urls = list()\n",
        "\n",
        "# Send a GET request to the website\n",
        "url = \"https://racing.hkjc.com/racing/information/English/Horse/HorseFormerName.aspx\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Find the <div> elements with the class name \"comm\"\n",
        "comm_divs = soup.find_all(\"div\", class_=\"commContent\")\n",
        "\n",
        "# Iterate over each <div> element\n",
        "for div in comm_divs:\n",
        "    # Find all the <a> elements within the <div>\n",
        "    links = div.find_all(\"a\")\n",
        "\n",
        "    # Extract and print the href attribute of each <a> element\n",
        "    for link in links:\n",
        "        href = link.get(\"href\")\n",
        "        if href and \"HorseId=\" in href:\n",
        "            horse_urls.append(\"https://racing.hkjc.com/\" + href + \"&Option=1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(horse_urls[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj8iNPd8xaI0",
        "outputId": "2268051f-51bb-4cb6-97d3-7fb93523509b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://racing.hkjc.com//racing/information/English/Horse/Horse.aspx?HorseId=HK_2022_H037&Option=1', 'https://racing.hkjc.com//racing/information/English/Horse/Horse.aspx?HorseId=HK_2022_H342&Option=1', 'https://racing.hkjc.com//racing/information/English/Horse/Horse.aspx?HorseId=HK_2020_E144&Option=1', 'https://racing.hkjc.com//racing/information/English/Horse/Horse.aspx?HorseId=HK_2022_H331&Option=1', 'https://racing.hkjc.com//racing/information/English/Horse/Horse.aspx?HorseId=HK_2021_G196&Option=1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMPNFAJHvkb_",
        "outputId": "bd0578b8-3024-480d-fa21-bb1f335c3a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# scrape from the web and store it into a dataframe\n",
        "def scrape_form_records(urls):\n",
        "\n",
        "    data = list()\n",
        "\n",
        "    for url in urls:\n",
        "\n",
        "        # Send a GET request to the website\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Create a BeautifulSoup object to parse the HTML content\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "        # Find the <div> elements with the class name \"comm\"\n",
        "        rows = soup.find_all(\"tr\", {'bgcolor': ['#F8F4EF', '#E7E4DF']})\n",
        "\n",
        "        # Extract the data from the rows and store it in a list of dictionaries\n",
        "\n",
        "        for key, row in enumerate(rows):\n",
        "            row_data = list()\n",
        "\n",
        "            for cell in row.find_all('td'):\n",
        "                value = cell.text.strip()\n",
        "                row_data.append(value)\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "    # Create a pandas DataFrame from the extracted data\n",
        "    df = pd.DataFrame(data, columns=['Race_Index', 'Place', 'Date',\n",
        "                                        'RC/Track/Course', 'Distance', 'Going',\n",
        "                                        'Race_Class', 'Draw', 'Rating', 'Trainer',\n",
        "                                        'Jockey', 'LBW', 'Win_Odds',\n",
        "                                        'Actual_Weight', 'Running_Position',\n",
        "                                        'Finish_Time', 'Declared_Horse_Weight',\n",
        "                                        'Gear', 'Video_Replay', 'Video_Replay_2'])\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "mU3yzhsKwVaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = scrape_form_records(horse_urls)\n",
        "print(table.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOKXuU2aAquC",
        "outputId": "3769af92-622f-45db-dcb7-7a5740d37148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Race_Index  Place      Date  RC/Track/Course Distance  Going  \\\n",
            "count       15210  15210     15210            15210    15210  15210   \n",
            "unique        838     24       496               17       12     11   \n",
            "top           449     01  12/02/24  ST / Turf / \"A\"     1200      G   \n",
            "freq           37   1599       136             1912     6180  11013   \n",
            "\n",
            "       Race_Class   Draw Rating   Trainer    Jockey    LBW Win_Odds  \\\n",
            "count       15210  15210  15210     15210     15210  15210    15210   \n",
            "unique         15     15    123        27        65    155      353   \n",
            "top             4      5     52  A S Cruz  Z Purton  1-1/4       10   \n",
            "freq         6882   1294   1240      1031      1229    606      575   \n",
            "\n",
            "       Actual_Weight Running_Position Finish_Time Declared_Horse_Weight  \\\n",
            "count          15210            15210       15210                 15210   \n",
            "unique            30             4983        3104                   375   \n",
            "top              126               --          --                    --   \n",
            "freq            1124              246         246                   239   \n",
            "\n",
            "         Gear Video_Replay Video_Replay_2  \n",
            "count   15210        15210          14971  \n",
            "unique    651            2              1  \n",
            "top        --                              \n",
            "freq     2920        14971          14971  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table.to_csv('./drive/MyDrive/aist4010_project/form_records.csv')"
      ],
      "metadata": {
        "id": "NlbNbXtnJHe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}